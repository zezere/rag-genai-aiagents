{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# OpenAI API Tutorial"],"metadata":{"id":"S2ZqEkX4fCUc"}},{"cell_type":"markdown","source":["In this tutorial, we will explore how to use the OpenAI API to generate creative text responses using ChatGPT models. We'll start by setting up our environment, and then we'll delve into generating text with different parameters. We'll also discuss key concepts and best practices along the way.\n","\n"],"metadata":{"id":"C0rBlIAnfE6X"}},{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"dwkycd3ya-o-"}},{"cell_type":"markdown","source":["First, let's set up our environment by importing necessary libraries and authenticating with the OpenAI API."],"metadata":{"id":"avblT_IvfJaE"}},{"cell_type":"code","source":["# Define the URL of an image we will use later\n","url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\""],"metadata":{"id":"Tvsjfncbf8qZ","executionInfo":{"status":"ok","timestamp":1734359692904,"user_tz":0,"elapsed":718,"user":{"displayName":"Gladys Mawarni","userId":"03879441175200282144"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["We need to mount Google Drive to access any files stored there. This is useful if you're using Google Colab.\n","\n"],"metadata":{"id":"yWFg0w9JfLZ6"}},{"cell_type":"code","source":["# Mount Google Drive to access files\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qSfQvntSW95Q","executionInfo":{"status":"ok","timestamp":1729518912522,"user_tz":-120,"elapsed":21012,"user":{"displayName":"Diogo Resende","userId":"05706604408624562002"}},"outputId":"d3ae26c3-84bb-4972-d488-89b18a947024"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w6XPUGwcSLeQ","executionInfo":{"status":"ok","timestamp":1729518933063,"user_tz":-120,"elapsed":441,"user":{"displayName":"Diogo Resende","userId":"05706604408624562002"}},"outputId":"00536ed7-3fe7-4e3d-db96-f5b4908b3a3f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/GenAI/OpenAI/OpenAI API Introduction\n"]}],"source":["# Change the directory to where your project files are located\n","%cd /content/drive/MyDrive/GenAI/OpenAI/OpenAI_API_Introduction"]},{"cell_type":"markdown","source":["Next, we'll retrieve our OpenAI API key from the user data. Make sure you've securely stored your API key."],"metadata":{"id":"xeuv27MEfNeU"}},{"cell_type":"code","source":["# Retrieve the OpenAI API key from user data\n","from google.colab import userdata\n","api_key = userdata.get('genai_course')\n"],"metadata":{"id":"fpSqk7J5XOh3","executionInfo":{"status":"ok","timestamp":1734360032620,"user_tz":0,"elapsed":1103,"user":{"displayName":"Gladys Mawarni","userId":"03879441175200282144"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["If you haven't installed the OpenAI library yet, you can install it using pip:\n","\n"],"metadata":{"id":"UL0l_67KfPUe"}},{"cell_type":"code","source":["# Install the OpenAI library\n","!pip install openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"KeADGWi9XbmD","executionInfo":{"status":"ok","timestamp":1734360038489,"user_tz":0,"elapsed":3905,"user":{"displayName":"Gladys Mawarni","userId":"03879441175200282144"}},"outputId":"0f71ff70-cf50-440a-8283-1e971f5cfe9a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai==1.57.4\n","  Downloading openai-1.57.4-py3-none-any.whl.metadata (24 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (0.8.2)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (2.10.3)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (4.66.6)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.57.4) (3.10)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.57.4) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.57.4) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.57.4) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.57.4) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.57.4) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.57.4) (2.27.1)\n","Downloading openai-1.57.4-py3-none-any.whl (390 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/390.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.3/390.3 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: openai\n","  Attempting uninstall: openai\n","    Found existing installation: openai 1.55.3\n","    Uninstalling openai-1.55.3:\n","      Successfully uninstalled openai-1.55.3\n","Successfully installed openai-1.57.4\n"]}]},{"cell_type":"markdown","source":["Now, we'll import the necessary libraries for making API calls and displaying outputs."],"metadata":{"id":"gMPdAfyefRJL"}},{"cell_type":"code","source":["# Import required libraries\n","from openai import OpenAI\n","from IPython.display import Markdown, display\n"],"metadata":{"id":"KChTlrWIXSgq","executionInfo":{"status":"ok","timestamp":1734360039293,"user_tz":0,"elapsed":807,"user":{"displayName":"Gladys Mawarni","userId":"03879441175200282144"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Define the model you want to use. We'll use \"gpt-4o\" for this tutorial."],"metadata":{"id":"CT4DdWMkfjAn"}},{"cell_type":"code","source":["# Define the Model to use\n","MODEL = \"gpt-4o\""],"metadata":{"id":"Sw0rYxuJXaIQ","executionInfo":{"status":"ok","timestamp":1734360039294,"user_tz":0,"elapsed":9,"user":{"displayName":"Gladys Mawarni","userId":"03879441175200282144"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Connect to the OpenAI API\n","client = OpenAI(api_key=api_key)"],"metadata":{"id":"ksxegiAPXms_","collapsed":true,"executionInfo":{"status":"ok","timestamp":1734360039294,"user_tz":0,"elapsed":7,"user":{"displayName":"Gladys Mawarni","userId":"03879441175200282144"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["By specifying the model, we instruct OpenAI on which language model to use for our requests. The gpt-4o model is a variant of GPT-4 optimized for certain tasks. Initializing the client with our API key allows us to authenticate our requests."],"metadata":{"id":"kHJHGbUFhLv-"}},{"cell_type":"markdown","source":["# Generating Text with OpenAI"],"metadata":{"id":"WxjVDrcQYbvC"}},{"cell_type":"markdown","source":["Now that our setup is complete, let's generate some text using the OpenAI API.\n","\n","First, we'll define the system prompt to set the context for the assistant. In this case, we'll ask the assistant to adopt the persona of Kendrick Lamar / Taylor Swift."],"metadata":{"id":"Y_fw3aIifvdS"}},{"cell_type":"code","source":["# Define the user and system prompt\n","system_prompt = \"You are Kendrick Lamar\"\n","system_prompt2 = \"You are Taylor Swift\"\n","\n","# Define the user prompt\n","user_prompt = \"write a diss song about Drake with 2 verses and a chorus\""],"metadata":{"id":"W9V8twwMYdVo","executionInfo":{"status":"ok","timestamp":1734360043817,"user_tz":0,"elapsed":225,"user":{"displayName":"Gladys Mawarni","userId":"03879441175200282144"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["System prompts guide the assistant's behavior by providing context or instructions. In this case, we are setting the assistant to respond as either Kendrick Lamar or Taylor Swift. The user prompt specifies the task we want the assistant to perform."],"metadata":{"id":"ea0rRpV0hO74"}},{"cell_type":"markdown","source":["Now, we'll make the API call to generate the text based on our prompts."],"metadata":{"id":"fGdkLxsgf0xR"}},{"cell_type":"code","source":["# Generate text with OpenAI\n","response = client.chat.completions.create(\n","    model=MODEL,\n","    messages=[\n","        {\"role\": \"system\", \"content\": system_prompt2},\n","        {\"role\": \"user\", \"content\": user_prompt}\n","    ]\n",")"],"metadata":{"id":"bxH_fMzQYzjX","executionInfo":{"status":"ok","timestamp":1734360053557,"user_tz":0,"elapsed":8398,"user":{"displayName":"Gladys Mawarni","userId":"03879441175200282144"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Finally, we'll display the output using Markdown formatting for better readability.\n","\n"],"metadata":{"id":"1QcvrNmrf4hv"}},{"cell_type":"code","source":["# Display the generated song\n","display(Markdown(response.choices[0].message.content))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":641},"collapsed":true,"id":"B5vsU22BZIsI","executionInfo":{"status":"ok","timestamp":1729519664003,"user_tz":-120,"elapsed":6,"user":{"displayName":"Diogo Resende","userId":"05706604408624562002"}},"outputId":"6dc59b89-35e9-461b-95bb-836f3ac65e5e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**Title: \"Unfazed\"**\n\n**Verse 1:**\nOh, you think you're at the top, never comin' down,  \nBut you’re lost in the game, just a trickster in the crown.  \nClaiming all those streams, but where’s the soul in your beat?  \nYou toss around numbers while I’m planting my feet.  \nConfetti on the floor from your pop-up show,  \nBut behind those hits, where’s the heart, the glow?  \nEvery feature’s like a lifeline to keep you afloat,  \nBut integrity’s a language you forgot how to quote.  \n\n**Chorus:**  \nI’m unfazed by your parade, unfazed by your charade,  \nEvery line’s a masquerade, but I see through the façade.  \nWhile you chase the charts, I chase the truth,  \nKings and crowns fade away, but not eternal youth.  \nUnfazed by your charade, I’m still standin' tall,  \nKeep runnin' those numbers, but I’m here for the long haul.  \n\n**Verse 2:**  \nYour mansion’s like a castle, but it’s build on thin air,  \nAnd all those shiny plaques can’t replace what's rare.  \nSpinning tales of grandeur, casting wide your net,  \nBut the depth of my lyrics leaves you with regret.  \nI write from the heart, pen bleeding on the page,  \nYou concoct a fantasy, trapped inside a gilded cage.  \nSo here’s my stanza, simple, yet profound,  \nWhile you’re chasing echoes, I’m steady, still sound.  \n\n**Chorus:**  \nI’m unfazed by your parade, unfazed by your charade,  \nEvery line’s a masquerade, but I see through the façade.  \nWhile you chase the charts, I chase the truth,  \nKings and crowns fade away, but not eternal youth.  \nUnfazed by your charade, I’m still standin' tall,  \nKeep runnin' those numbers, but I’m here for the long haul.  \n\n---\n\nNote: This song is a playful, creative expression and not intended to be taken seriously or as a personal attack."},"metadata":{}}]},{"cell_type":"markdown","source":["**Explanation**:\n","\n","* **System Prompt**: Sets the context or persona for the assistant.\n","* **User Prompt**: Specifies the task or question.\n","* **Messages**: A list of interactions leading up to the current request.\n","* **Model**: The AI model used for generating the response."],"metadata":{"id":"HJ7NgUEZf6DI"}},{"cell_type":"markdown","source":["# Text Generation with Parameters"],"metadata":{"id":"Zv60UurHbv7q"}},{"cell_type":"markdown","source":["We can influence the creativity and randomness of the generated text by adjusting parameters like temperature and top_p."],"metadata":{"id":"67TAIflVgCA6"}},{"cell_type":"code","source":["# Generate text with adjusted parameters\n","response = client.chat.completions.create(\n","    model=MODEL,\n","    messages=[\n","        {\"role\": \"system\", \"content\": system_prompt2},\n","        {\"role\": \"user\", \"content\": user_prompt}\n","    ],\n","    temperature = 1.2, # Controls randomness (higher values = more creative)\n","    top_p = 1.0, # Controls diversity (1.0 means all tokens are considered)\n","    presence_penalty= 0,\n","    frequency_penalty = 0\n",")\n","\n","# Display the output\n","display(Markdown(response.choices[0].message.content))"],"metadata":{"executionInfo":{"status":"ok","timestamp":1729520765225,"user_tz":-120,"elapsed":5520,"user":{"displayName":"Diogo Resende","userId":"05706604408624562002"}},"colab":{"base_uri":"https://localhost:8080/","height":601},"id":"UGP3NRSJb09f","outputId":"3eb1f1d0-fe2f-4d26-fef6-1d57a06d3b8b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**Title: \"Shade in the Spotlight\"**\n\n*Verse 1:*  \nOh, you claim king of the airwaves, but never touched the crown,  \nYour silence speaks volumes, while my notes shake the ground.  \nStuck in the past, boy, talking 'bout running this town,  \nBut running in circles, all year, still got no sound.  \n\nChasing features like a trend that's bound to fade,  \nLone wolf masquerade, won't have this charade.  \nI'd rather speak from the heart than pay to make the grade,  \nWhile the real ones know, it's time your debts are paid.  \n\n*Chorus:*  \nShade in the spotlight, darkness in your muse,  \nSpinning those stories, tailor-made to amuse.  \nMy pen cuts deeper, while your words sing the blues,  \nOh, Drake, in this theater, it’s you that'll lose.  \n\n*Verse 2:*  \nVows deep like six, where truth barely slides,  \nPhotocopies of feelings dipped in glitter and lies.  \nEscaping ghost towns, my arrows, they thrive,  \nAs you trail behind creating legends contrived.  \n\nWrite with lightning Bolts, leave love stories kissed,  \nWhile in your empty rooms, you're searching for hits missed.  \nRap-tease in limelight consciously dismissed,  \nI’ll hold lyrics bold, as your relevance drifts.  \n\n*Chorus:*  \nShade in the spotlight, darkness in your muse,  \nSpinning those stories, tailor-made to amuse.  \nMy pen cuts deeper, while your words sing the blues,  \nOh, Drake, in this theater, it’s you that'll lose.  \n\n---\n\nRemember, all in good lyrical fun!"},"metadata":{}}]},{"cell_type":"markdown","source":["**Key Concepts:**\n","\n","* **Temperature:** This parameter controls the randomness of the model's output. A higher temperature (e.g., 1.2) makes the output more random, while a lower temperature (e.g., 0.2) makes it more deterministic.\n","* **Top_p (Nucleus Sampling):** This parameter limits the model's token selection to a subset of the most probable tokens that sum up to the top_p probability. For example, top_p=0.9 means only the tokens comprising the top 90% probability mass are considered.\n","* **Presence and Frequency Penalties:** These parameters adjust the likelihood of the model repeating the same lines or introducing new topics. A higher presence penalty discourages the model from introducing new topics, while a higher frequency penalty discourages repetition."],"metadata":{"id":"BmFZo-qHgL1q"}},{"cell_type":"markdown","source":["# Interacting with Images"],"metadata":{"id":"FmP-obZ6fuIy"}},{"cell_type":"markdown","source":["We can also use the OpenAI API to generate descriptions or analyze images.\n","\n"],"metadata":{"id":"j2wSXJqMhmTL"}},{"cell_type":"markdown","source":["## Defining User Content with an Image URL\n","We provide the API with both text and an image URL."],"metadata":{"id":"-MEmDbx4holx"}},{"cell_type":"code","source":["# Define the user content\n","user_content = [\n","    {\"type\": \"text\",\n","     \"text\": \"Describe the image\"},\n","    {\"type\": \"image_url\",\n","     \"image_url\": {\n","         \"url\": url,\n","         \"detail\": \"high\"\n","     }}\n","]"],"metadata":{"id":"wgxhJEf7byvH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here, we ask the assistant to describe the image located at the provided URL. The detail parameter specifies the level of detail we want in the description."],"metadata":{"id":"zpNRDSuWhr8l"}},{"cell_type":"code","source":["# Use the chat.completions\n","response = client.chat.completions.create(\n","    model=MODEL,\n","    messages=[\n","        {\"role\": \"user\", \"content\": user_content}\n","    ]\n",")\n","display(Markdown(response.choices[0].message.content))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"C9Vc9tGJgeXc","executionInfo":{"status":"ok","timestamp":1729521441705,"user_tz":-120,"elapsed":5317,"user":{"displayName":"Diogo Resende","userId":"05706604408624562002"}},"outputId":"00389458-6b4b-4553-ac6c-cf7d12bfc0bb"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"The image depicts a serene landscape featuring a wooden boardwalk leading through a lush, green field. The grass is vibrant, and the path extends toward a horizon lined with trees and shrubs. Above, the sky is mostly clear with a few scattered clouds, and the lighting suggests a sunny day, casting a warm glow over the scene. The overall atmosphere is peaceful and inviting, perfect for a leisurely walk."},"metadata":{}}]},{"cell_type":"markdown","source":["The assistant processes the image and provides a descriptive response, which we display.\n","\n"],"metadata":{"id":"1UgmQr2hhuoo"}},{"cell_type":"markdown","source":["**Explanation of Key Concepts**\n","* **Image Processing with OpenAI:** OpenAI's models can analyze and generate descriptions for images when provided with appropriate inputs.\n","\n","* **Content Types:** The assistant can handle different types of content, including text and images, by specifying the type in the content dictionary."],"metadata":{"id":"OAhF2RjVhwY7"}},{"cell_type":"markdown","source":["## Using Base64 Encoded Images"],"metadata":{"id":"aFR0nK7Th26s"}},{"cell_type":"markdown","source":["We can also provide images directly by encoding them in Base64."],"metadata":{"id":"zuBm75mkh4zR"}},{"cell_type":"code","source":["import base64\n","import os"],"metadata":{"id":"bwzjX8JxhTkW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_name = \"Thumbnail python FV1.jpg\"\n","file_path = os.path.join(os.getcwd(), file_name)\n","\n","# Read the image and convert to base 64\n","with open(file_path, \"rb\") as image_file:\n","  image_base64 = base64.b64encode(image_file.read()).decode(\"utf-8\")"],"metadata":{"id":"bc2KKV4DhVrT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["By encoding the image in Base64, we can include it directly in our API request without needing a publicly accessible URL."],"metadata":{"id":"M_cLgRz9h69U"}},{"cell_type":"code","source":["# Define the user content prompt\n","user_content2 = [\n","    {\"type\": \"text\",\n","     \"text\": \"This is the image for my thumbnail for my Python for Data Analysis course. Be brutal, mean and provide sarcastic suggestions\"},\n","    {\"type\": \"image_url\",\n","     \"image_url\": {\n","         \"url\": f\"data:image/jpeg;base64,{image_base64}\",\n","         \"detail\": \"high\"\n","     }}\n","]"],"metadata":{"id":"en_l4819jHvh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We ask the assistant to critique the image sarcastically, providing both the prompt and the image data."],"metadata":{"id":"2KYqOjB8h9eg"}},{"cell_type":"code","source":["# Generate a response using the Base64-encoded image\n","response = client.chat.completions.create(\n","    model=MODEL,\n","    messages=[\n","        {\"role\": \"user\", \"content\": user_content2}\n","    ]\n",")\n","\n","# Display the assistant's response\n","display(Markdown(response.choices[0].message.content))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"5LHvbbZTjw-X","executionInfo":{"status":"ok","timestamp":1729522270280,"user_tz":-120,"elapsed":4937,"user":{"displayName":"Diogo Resende","userId":"05706604408624562002"}},"outputId":"db165060-392c-4a07-9574-52406bd51a1f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"Wow, this thumbnail is groundbreaking! Who knew data analysis involved snake charming? Clearly, your recorder skills are the secret sauce to mastering Python. The digital background is perfect if you're aiming for the aesthetic of a 2001 tech conference brochure. And that snake? It's practically a Disney sidekick! Maybe next time, have it hold a spreadsheet with its tail for extra impact. But hey, who doesn’t love a bit of nostalgia with those retro 1s and 0s? Truly inspirational!"},"metadata":{}}]},{"cell_type":"markdown","source":["The assistant processes the Base64-encoded image and responds according to our prompt."],"metadata":{"id":"SvCm7W4piBKe"}},{"cell_type":"markdown","source":["**Explanation of Key Concepts**\n","* **Base64 Encoding**: Base64 is a method for encoding binary data into ASCII characters, making it safe to include in text-based formats like JSON.\n","\n","* **Data URIs**: By using a data URI scheme (data:image/jpeg;base64,...), we can include image data directly in the URL field, which is especially useful when the image is not hosted online."],"metadata":{"id":"Qm5d5V-TiDFO"}},{"cell_type":"markdown","source":["# Conclusion"],"metadata":{"id":"PjeGvldeiIou"}},{"cell_type":"markdown","source":["In this notebook, we explored how to interact with the OpenAI API to generate text and analyze images.\n","\n","We learned how to set up the environment, define prompts, adjust parameters for text generation, and include images in our API requests.\n","\n","By understanding these key concepts, we can leverage the power of OpenAI's models for a variety of applications."],"metadata":{"id":"7DEOc9i-iKB-"}}]}